Loading tokenized datasets
Finished Loading tokenized datasets
Initialized new model
Device: cuda
At epoch 0, batch 0, loss = 10.856
At epoch 0, batch 1500, loss = 5.067
At epoch 0, batch 3000, loss = 4.592
At epoch 0, batch 4500, loss = 4.102
At epoch 0, batch 6000, loss = 3.861
At epoch 0, batch 7500, loss = 3.466
At epoch 0, batch 9000, loss = 3.182
At epoch 0, batch 10500, loss = 2.911
At epoch 0, batch 12000, loss = 2.818
At epoch 0, batch 13500, loss = 2.890
At epoch 0, batch 15000, loss = 2.419
At epoch 0, batch 16500, loss = 2.624
At epoch 0, batch 18000, loss = 2.529
At epoch 0, batch 19500, loss = 2.624
At epoch 0, batch 21000, loss = 2.463
At epoch 0, batch 22500, loss = 2.428
At epoch 0, batch 24000, loss = 2.330
#
Perplexity for the epoch is: 8.518 and the loss is 2289.320
#
At epoch 1, batch 0, loss = 2.127
At epoch 1, batch 1500, loss = 1.880
At epoch 1, batch 3000, loss = 1.941
At epoch 1, batch 4500, loss = 1.798
At epoch 1, batch 6000, loss = 1.788
At epoch 1, batch 7500, loss = 1.911
At epoch 1, batch 9000, loss = 1.949
At epoch 1, batch 10500, loss = 1.834
At epoch 1, batch 12000, loss = 1.892
At epoch 1, batch 13500, loss = 1.955
At epoch 1, batch 15000, loss = 1.700
At epoch 1, batch 16500, loss = 2.013
At epoch 1, batch 18000, loss = 2.004
At epoch 1, batch 19500, loss = 2.143
At epoch 1, batch 21000, loss = 1.967
At epoch 1, batch 22500, loss = 1.917
At epoch 1, batch 24000, loss = 1.911
#
Perplexity for the epoch is: 6.062 and the loss is 1925.808
#
At epoch 2, batch 0, loss = 1.808
At epoch 2, batch 1500, loss = 1.563
At epoch 2, batch 3000, loss = 1.665
At epoch 2, batch 4500, loss = 1.503
At epoch 2, batch 6000, loss = 1.467
At epoch 2, batch 7500, loss = 1.688
At epoch 2, batch 9000, loss = 1.678
At epoch 2, batch 10500, loss = 1.598
At epoch 2, batch 12000, loss = 1.639
At epoch 2, batch 13500, loss = 1.718
At epoch 2, batch 15000, loss = 1.478
At epoch 2, batch 16500, loss = 1.768
At epoch 2, batch 18000, loss = 1.842
At epoch 2, batch 19500, loss = 1.957
At epoch 2, batch 21000, loss = 1.783
At epoch 2, batch 22500, loss = 1.724
At epoch 2, batch 24000, loss = 1.757
#
Perplexity for the epoch is: 5.373 and the loss is 1796.915
#
At epoch 3, batch 0, loss = 1.653
At epoch 3, batch 1500, loss = 1.411
At epoch 3, batch 3000, loss = 1.541
At epoch 3, batch 4500, loss = 1.357
At epoch 3, batch 6000, loss = 1.349
At epoch 3, batch 7500, loss = 1.565
At epoch 3, batch 9000, loss = 1.554
At epoch 3, batch 10500, loss = 1.522
At epoch 3, batch 12000, loss = 1.503
At epoch 3, batch 13500, loss = 1.591
At epoch 3, batch 15000, loss = 1.377
At epoch 3, batch 16500, loss = 1.653
