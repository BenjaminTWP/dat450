Loading tokenized datasets
Finished Loading tokenized datasets
Initialized new model
Device: cuda
At epoch 0, batch 0, loss = 10.868
At epoch 0, batch 1500, loss = 4.512
At epoch 0, batch 3000, loss = 4.246
At epoch 0, batch 4500, loss = 4.007
At epoch 0, batch 6000, loss = 3.949
At epoch 0, batch 7500, loss = 3.931
At epoch 0, batch 9000, loss = 3.874
At epoch 0, batch 10500, loss = 3.717
At epoch 0, batch 12000, loss = 3.765
At epoch 0, batch 13500, loss = 4.109
At epoch 0, batch 15000, loss = 3.635
At epoch 0, batch 16500, loss = 3.763
At epoch 0, batch 18000, loss = 3.592
At epoch 0, batch 19500, loss = 3.836
At epoch 0, batch 21000, loss = 3.732
At epoch 0, batch 22500, loss = 3.549
At epoch 0, batch 24000, loss = 3.731
#
Perplexity for the epoch is: 35.512 and the loss is 3815.041
#
At epoch 1, batch 0, loss = 3.514
At epoch 1, batch 1500, loss = 3.483
At epoch 1, batch 3000, loss = 3.555
At epoch 1, batch 4500, loss = 3.473
At epoch 1, batch 6000, loss = 3.492
At epoch 1, batch 7500, loss = 3.495
At epoch 1, batch 9000, loss = 3.496
At epoch 1, batch 10500, loss = 3.415
At epoch 1, batch 12000, loss = 3.462
At epoch 1, batch 13500, loss = 3.791
At epoch 1, batch 15000, loss = 3.360
At epoch 1, batch 16500, loss = 3.460
At epoch 1, batch 18000, loss = 3.317
At epoch 1, batch 19500, loss = 3.535
At epoch 1, batch 21000, loss = 3.343
At epoch 1, batch 22500, loss = 3.249
At epoch 1, batch 24000, loss = 3.360
#
Perplexity for the epoch is: 25.137 and the loss is 3445.757
#
At epoch 2, batch 0, loss = 3.133
At epoch 2, batch 1500, loss = 3.093
At epoch 2, batch 3000, loss = 3.151
At epoch 2, batch 4500, loss = 3.035
At epoch 2, batch 6000, loss = 2.973
At epoch 2, batch 7500, loss = 2.930
At epoch 2, batch 9000, loss = 2.968
At epoch 2, batch 10500, loss = 2.883
At epoch 2, batch 12000, loss = 2.897
At epoch 2, batch 13500, loss = 3.184
At epoch 2, batch 15000, loss = 2.737
At epoch 2, batch 16500, loss = 2.977
At epoch 2, batch 18000, loss = 2.806
At epoch 2, batch 19500, loss = 2.970
At epoch 2, batch 21000, loss = 2.809
At epoch 2, batch 22500, loss = 2.678
At epoch 2, batch 24000, loss = 2.706
#
Perplexity for the epoch is: 13.041 and the loss is 2744.498
#
At epoch 3, batch 0, loss = 2.504
At epoch 3, batch 1500, loss = 2.318
At epoch 3, batch 3000, loss = 2.432
At epoch 3, batch 4500, loss = 2.268
At epoch 3, batch 6000, loss = 2.214
At epoch 3, batch 7500, loss = 2.244
At epoch 3, batch 9000, loss = 2.203
At epoch 3, batch 10500, loss = 2.235
At epoch 3, batch 12000, loss = 2.221
At epoch 3, batch 13500, loss = 2.351
At epoch 3, batch 15000, loss = 2.043
At epoch 3, batch 16500, loss = 2.250
At epoch 3, batch 18000, loss = 2.201
At epoch 3, batch 19500, loss = 2.389
At epoch 3, batch 21000, loss = 2.205
At epoch 3, batch 22500, loss = 2.188
At epoch 3, batch 24000, loss = 2.269
#
Perplexity for the epoch is: 8.179 and the loss is 2245.923
#
At epoch 4, batch 0, loss = 2.020
At epoch 4, batch 1500, loss = 1.818
At epoch 4, batch 3000, loss = 1.967
At epoch 4, batch 4500, loss = 1.790
At epoch 4, batch 6000, loss = 1.839
At epoch 4, batch 7500, loss = 1.937
At epoch 4, batch 9000, loss = 1.934
At epoch 4, batch 10500, loss = 1.925
At epoch 4, batch 12000, loss = 1.935
At epoch 4, batch 13500, loss = 2.038
At epoch 4, batch 15000, loss = 1.752
At epoch 4, batch 16500, loss = 1.981
At epoch 4, batch 18000, loss = 2.044
At epoch 4, batch 19500, loss = 2.178
At epoch 4, batch 21000, loss = 1.935
At epoch 4, batch 22500, loss = 2.001
At epoch 4, batch 24000, loss = 2.033
#
Perplexity for the epoch is: 6.861 and the loss is 2058.143
#
At epoch 5, batch 0, loss = 1.854
At epoch 5, batch 1500, loss = 1.617
At epoch 5, batch 3000, loss = 1.786
At epoch 5, batch 4500, loss = 1.679
At epoch 5, batch 6000, loss = 1.664
At epoch 5, batch 7500, loss = 1.812
At epoch 5, batch 9000, loss = 1.792
At epoch 5, batch 10500, loss = 1.773
At epoch 5, batch 12000, loss = 1.768
At epoch 5, batch 13500, loss = 1.862
At epoch 5, batch 15000, loss = 1.597
At epoch 5, batch 16500, loss = 1.813
At epoch 5, batch 18000, loss = 1.982
At epoch 5, batch 19500, loss = 2.050
At epoch 5, batch 21000, loss = 1.798
At epoch 5, batch 22500, loss = 1.873
At epoch 5, batch 24000, loss = 1.899
#
Perplexity for the epoch is: 6.267 and the loss is 1961.344
#
At epoch 6, batch 0, loss = 1.769
At epoch 6, batch 1500, loss = 1.510
At epoch 6, batch 3000, loss = 1.670
At epoch 6, batch 4500, loss = 1.565
At epoch 6, batch 6000, loss = 1.581
At epoch 6, batch 7500, loss = 1.701
At epoch 6, batch 9000, loss = 1.694
At epoch 6, batch 10500, loss = 1.697
At epoch 6, batch 12000, loss = 1.653
At epoch 6, batch 13500, loss = 1.761
At epoch 6, batch 15000, loss = 1.521
At epoch 6, batch 16500, loss = 1.734
At epoch 6, batch 18000, loss = 1.867
At epoch 6, batch 19500, loss = 1.956
At epoch 6, batch 21000, loss = 1.724
At epoch 6, batch 22500, loss = 1.801
At epoch 6, batch 24000, loss = 1.822
#
Perplexity for the epoch is: 5.963 and the loss is 1908.253
#
At epoch 7, batch 0, loss = 1.693
At epoch 7, batch 1500, loss = 1.439
At epoch 7, batch 3000, loss = 1.631
At epoch 7, batch 4500, loss = 1.493
At epoch 7, batch 6000, loss = 1.507
At epoch 7, batch 7500, loss = 1.612
At epoch 7, batch 9000, loss = 1.628
At epoch 7, batch 10500, loss = 1.625
At epoch 7, batch 12000, loss = 1.586
At epoch 7, batch 13500, loss = 1.689
At epoch 7, batch 15000, loss = 1.452
At epoch 7, batch 16500, loss = 1.651
At epoch 7, batch 18000, loss = 1.804
At epoch 7, batch 19500, loss = 1.921
At epoch 7, batch 21000, loss = 1.658
At epoch 7, batch 22500, loss = 1.737
At epoch 7, batch 24000, loss = 1.747
#
Perplexity for the epoch is: 5.727 and the loss is 1865.122
#
At epoch 8, batch 0, loss = 1.677
At epoch 8, batch 1500, loss = 1.354
At epoch 8, batch 3000, loss = 1.585
At epoch 8, batch 4500, loss = 1.464
At epoch 8, batch 6000, loss = 1.433
At epoch 8, batch 7500, loss = 1.589
At epoch 8, batch 9000, loss = 1.600
At epoch 8, batch 10500, loss = 1.579
At epoch 8, batch 12000, loss = 1.541
At epoch 8, batch 13500, loss = 1.635
At epoch 8, batch 15000, loss = 1.393
At epoch 8, batch 16500, loss = 1.601
At epoch 8, batch 18000, loss = 1.772
At epoch 8, batch 19500, loss = 1.919
At epoch 8, batch 21000, loss = 1.607
At epoch 8, batch 22500, loss = 1.699
At epoch 8, batch 24000, loss = 1.733
#
Perplexity for the epoch is: 5.571 and the loss is 1835.444
#
At epoch 9, batch 0, loss = 1.652
At epoch 9, batch 1500, loss = 1.322
At epoch 9, batch 3000, loss = 1.533
At epoch 9, batch 4500, loss = 1.438
At epoch 9, batch 6000, loss = 1.366
At epoch 9, batch 7500, loss = 1.564
At epoch 9, batch 9000, loss = 1.582
At epoch 9, batch 10500, loss = 1.528
At epoch 9, batch 12000, loss = 1.506
At epoch 9, batch 13500, loss = 1.630
At epoch 9, batch 15000, loss = 1.361
At epoch 9, batch 16500, loss = 1.527
At epoch 9, batch 18000, loss = 1.726
At epoch 9, batch 19500, loss = 1.865
At epoch 9, batch 21000, loss = 1.583
At epoch 9, batch 22500, loss = 1.666
At epoch 9, batch 24000, loss = 1.708
#
Perplexity for the epoch is: 5.463 and the loss is 1814.619
#

#Saving to ..
#
