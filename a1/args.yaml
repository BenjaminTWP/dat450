arguments:
  embedding_size:
    type: int
    help: "Size of the embedding"
    default: 256

  hidden_size:
    type: int
    help: "Size of the hidden layers"
    default: 512

  num_layers:
    type: int
    help: "Number of layers in the LSTM"
    default: 4

  npreds:
    type: int
    help: "Number of topk words returned for prediction"
    default: 10

  run:
    type: str
    help: "What we want to do (create tokenizer, train, predict)"
    default: "predict"

  tf:
    type: str
    help: "Location of the training file"
    default: "/data/courses/2025_dat450_dit247/assignments/a1/train.txt"

  vf:
    type: str
    help: "Location of the training file"
    default: "/data/courses/2025_dat450_dit247/assignments/a1/val.txt"

  tokenizer_file:
    type: str
    help: "Location of the training file"
    default: "a1/tokenizer.pkl"

  output_dir:
    type: str
    help: "Output directory of the saved model"
    default: "a1/trainer_output/"
  